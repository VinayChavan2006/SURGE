{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinayChavan2006/SURGE/blob/main/paco-data-viewer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt2gAgZzvjxd",
        "outputId": "c2b58c18-b2f9-4bb0-c2f5-f6e5ebb457f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 15868, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 15868 (delta 44), reused 14 (delta 14), pack-reused 15782 (from 3)\u001b[K\n",
            "Receiving objects: 100% (15868/15868), 6.42 MiB | 14.80 MiB/s, done.\n",
            "Resolving deltas: 100% (11547/11547), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/paco.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0LzVk_svlkx",
        "outputId": "20d48957-8879-447c-9f0a-b30c3a399581"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'paco'...\n",
            "remote: Enumerating objects: 158, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 158 (delta 12), reused 12 (delta 9), pack-reused 138 (from 1)\u001b[K\n",
            "Receiving objects: 100% (158/158), 1.56 MiB | 5.85 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd detectron2\n",
        "!pip install -e .\n",
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZPMbbIFGzOoC",
        "outputId": "c1672ddd-3db4-4316-eb8f-cf51231b52eb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/detectron2\n",
            "Obtaining file:///content/detectron2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.9)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.2.1)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.72.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: pathspec, mypy-extensions, iopath, hydra-core, black, detectron2\n",
            "  Attempting uninstall: iopath\n",
            "    Found existing installation: iopath 0.1.10\n",
            "    Uninstalling iopath-0.1.10:\n",
            "      Successfully uninstalled iopath-0.1.10\n",
            "  Running setup.py develop for detectron2\n",
            "Successfully installed black-25.1.0 detectron2-0.6 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.1.0 pathspec-0.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "iopath"
                ]
              },
              "id": "cd51d6b530bb438f95277b536c90d7f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir()\n",
        "%cd paco"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrvbL-if3PB0",
        "outputId": "40de1922-1ca2-447d-f7ac-aeef8d58cf39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/paco\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O3Td_bJ13I_k",
        "outputId": "6916aed6-cdc3-4ae9-be80-9107c00c5433"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8 (from -r requirements.txt (line 1))\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision 0703e08a5f589f7503a3fbfce41309c80204eec8) to /tmp/pip-install-ai30s0_9/detectron2_dc42df196a79459db33addf699d41a67\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-install-ai30s0_9/detectron2_dc42df196a79459db33addf699d41a67\n",
            "  Running command git rev-parse -q --verify 'sha^0703e08a5f589f7503a3fbfce41309c80204eec8'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/detectron2.git 0703e08a5f589f7503a3fbfce41309c80204eec8\n",
            "  Running command git checkout -q 0703e08a5f589f7503a3fbfce41309c80204eec8\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 0703e08a5f589f7503a3fbfce41309c80204eec8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ego4d (from -r requirements.txt (line 2))\n",
            "  Downloading ego4d-1.7.3.tar.gz (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lvis (from -r requirements.txt (line 3))\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (6.5.7)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.11.0.86)\n",
            "Collecting submitit (from -r requirements.txt (line 6))\n",
            "  Downloading submitit-1.5.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (2.0.9)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (2.18.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (0.1.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (1.3.2)\n",
            "Collecting black==22.3.0 (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading black-22.3.0-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (1.0.15)\n",
            "Collecting fairscale (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black==22.3.0->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (8.2.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black==22.3.0->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (4.3.8)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black==22.3.0->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black==22.3.0->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (1.1.0)\n",
            "Collecting boto3 (from ego4d->-r requirements.txt (line 2))\n",
            "  Downloading boto3-1.38.32-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from ego4d->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Collecting dataclasses_json (from ego4d->-r requirements.txt (line 2))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lvis->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.11/dist-packages (from lvis->-r requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from lvis->-r requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.11/dist-packages (from lvis->-r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from lvis->-r requirements.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from lvis->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from lvis->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (6.4.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (25.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (5.8.1)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (7.16.6)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (6.17.1)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 6)) (4.14.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (4.58.1)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->-r requirements.txt (line 4)) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 4)) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook->-r requirements.txt (line 4)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 4)) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 4)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 4)) (2.19.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->-r requirements.txt (line 4)) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->-r requirements.txt (line 4)) (4.24.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->-r requirements.txt (line 4)) (21.2.0)\n",
            "Collecting botocore<1.39.0,>=1.38.32 (from boto3->ego4d->-r requirements.txt (line 2))\n",
            "  Downloading botocore-1.38.32-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->ego4d->-r requirements.txt (line 2))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->ego4d->-r requirements.txt (line 2))\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses_json->ego4d->-r requirements.txt (line 2))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses_json->ego4d->-r requirements.txt (line 2))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook->-r requirements.txt (line 4)) (7.34.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook->-r requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (1.72.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (0.21.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (0.32.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.39.0,>=1.38.32->boto3->ego4d->-r requirements.txt (line 2)) (2.4.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 4))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 4)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 4)) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 4)) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 4)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 4)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 4)) (0.25.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->fairscale->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->-r requirements.txt (line 4)) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook->-r requirements.txt (line 4)) (2.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->-r requirements.txt (line 4)) (2.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->-r requirements.txt (line 4)) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 4)) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm->detectron2@ git+https://github.com/facebookresearch/detectron2.git@0703e08a5f589f7503a3fbfce41309c80204eec8->-r requirements.txt (line 1)) (2025.4.26)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->-r requirements.txt (line 4)) (1.3.1)\n",
            "Downloading black-22.3.0-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Downloading submitit-1.5.3-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.38.32-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading botocore-1.38.32-py3-none-any.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: detectron2, ego4d, fairscale\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp311-cp311-linux_x86_64.whl size=6074974 sha256=fa32bbd3cb525133a2a558aea2187b49765a673465e64f189e8cb1856eff4159\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/9f/6a/844768c934d37500b9f99f56bf74f82e307125503a4f9521bf\n",
            "  Building wheel for ego4d (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ego4d: filename=ego4d-1.7.3-py3-none-any.whl size=118282 sha256=a55f1cbb4f9d9953e260adb83fc9da0e586c6f2072c6c509fc649aa28537a6d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/df/07/e6fbe27d3ca2410baf3e04485d356eda052539f27ac2d52d8a\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332208 sha256=3abfe5339d42d47ddcb0b26be3a3a082549629ebc02266d6aeac94b7a7e1d696\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/ef/96/5044bde220b2ea299bdc6ec05051e0ef187fad45b341d1c273\n",
            "Successfully built detectron2 ego4d fairscale\n",
            "Installing collected packages: typing-inspect, submitit, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, marshmallow, jmespath, jedi, black, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dataclasses_json, botocore, s3transfer, nvidia-cusolver-cu12, lvis, boto3, fairscale, ego4d, detectron2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: black\n",
            "    Found existing installation: black 25.1.0\n",
            "    Uninstalling black-25.1.0:\n",
            "      Successfully uninstalled black-25.1.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: detectron2\n",
            "    Found existing installation: detectron2 0.6\n",
            "    Uninstalling detectron2-0.6:\n",
            "      Successfully uninstalled detectron2-0.6\n",
            "Successfully installed black-22.3.0 boto3-1.38.32 botocore-1.38.32 dataclasses_json-0.6.7 detectron2-0.6 ego4d-1.7.3 fairscale-0.4.13 jedi-0.19.2 jmespath-1.0.1 lvis-0.5.3 marshmallow-3.26.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 s3transfer-0.13.0 submitit-1.5.3 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "detectron2"
                ]
              },
              "id": "5698ab75d056400bac0c3e54a163c749"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify dataset name. Available options:\n",
        "# dataset_name = \"paco_lvis_v1_train\"\n",
        "# dataset_name = \"paco_lvis_v1_val\"\n",
        "# dataset_name = \"paco_lvis_v1_test\"\n",
        "# dataset_name = \"paco_ego4d_v1_train\"\n",
        "# dataset_name = \"paco_ego4d_v1_val\"\n",
        "# dataset_name = \"paco_ego4d_v1_test\"\n",
        "dataset_name = \"paco_lvis_v1_test\""
      ],
      "metadata": {
        "id": "knRVQLE2vrkQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.getcwd()\n",
        "# %mkdir -p ./datasets/paco/annotations\n",
        "%cd ./datasets/paco/annotations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJrGQwY0A7Ze",
        "outputId": "1ac9bce3-2860-422a-a366-87e11b61714a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/paco/datasets/paco/annotations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/paco/annotations/paco_lvis_v1.zip\n",
        "!wget https://dl.fbaipublicfiles.com/paco/annotations/paco_ego4d_v1.zip\n",
        "!diff <(sha256sum paco_lvis_v1.zip) <(echo \"02ac4edb22c251e07853e6231d69aec3fad0a180f03de2f8c880650322debc80  paco_lvis_v1.zip\")\n",
        "!diff <(sha256sum paco_ego4d_v1.zip) <(echo \"9a2de524dd64ad8f807f0d1ad2e96de590b9fb222e55192ccfdd7b7b09b89252  paco_ego4d_v1.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyC_lzeEBk_A",
        "outputId": "cf698d45-53d0-4c24-a477-2b4a11aec5e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-07 10:54:36--  https://dl.fbaipublicfiles.com/paco/annotations/paco_lvis_v1.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.169.137.39, 3.169.137.48, 3.169.137.27, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.169.137.39|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 134514081 (128M) [application/zip]\n",
            "Saving to: ‘paco_lvis_v1.zip’\n",
            "\n",
            "paco_lvis_v1.zip    100%[===================>] 128.28M  34.9MB/s    in 4.2s    \n",
            "\n",
            "2025-06-07 10:54:41 (30.7 MB/s) - ‘paco_lvis_v1.zip’ saved [134514081/134514081]\n",
            "\n",
            "--2025-06-07 10:54:41--  https://dl.fbaipublicfiles.com/paco/annotations/paco_ego4d_v1.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.169.137.39, 3.169.137.48, 3.169.137.27, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.169.137.39|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 148422207 (142M) [application/zip]\n",
            "Saving to: ‘paco_ego4d_v1.zip’\n",
            "\n",
            "paco_ego4d_v1.zip   100%[===================>] 141.55M  38.0MB/s    in 4.4s    \n",
            "\n",
            "2025-06-07 10:54:46 (31.9 MB/s) - ‘paco_ego4d_v1.zip’ saved [148422207/148422207]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip paco_lvis_v1.zip\n",
        "!unzip paco_ego4d_v1.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3MlmxIsCFO-",
        "outputId": "b5acedd4-09f6-4bea-82be-40b4d2df7535"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  paco_lvis_v1.zip\n",
            "  inflating: paco_lvis_v1_test.json  \n",
            "  inflating: paco_lvis_v1_train.json  \n",
            "  inflating: paco_lvis_v1_val.json   \n",
            "Archive:  paco_ego4d_v1.zip\n",
            "  inflating: paco_ego4d_v1_test.json  \n",
            "  inflating: paco_ego4d_v1_train.json  \n",
            "  inflating: paco_ego4d_v1_val.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../../../\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "lJKr-9W4Cvn4",
        "outputId": "ee12ebe6-5b88-4262-b577-a50411a48d94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/paco\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/paco'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from paco.data.datasets.builtin import _PREDEFINED_PACO\n",
        "\n",
        "# Derived parameters.\n",
        "dataset_file_name, image_root_dir = _PREDEFINED_PACO[dataset_name]\n",
        "print(dataset_file_name)\n",
        "# Load dataset.\n",
        "with open(dataset_file_name) as f:\n",
        "    dataset = json.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GG7amKCv9Qk",
        "outputId": "56b48c2e-0525-475e-b4f1-c8f65b819b3a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets/paco/annotations/paco_lvis_v1_test.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_obj_and_part_anns(annotations):\n",
        "    \"\"\"\n",
        "    Returns a map between an object annotation ID and\n",
        "    (object annotation, list of part annotations) pair.\n",
        "    \"\"\"\n",
        "    ann_id_to_anns = {ann[\"id\"]: (ann, []) for ann in annotations if ann[\"id\"] == ann[\"obj_ann_id\"]}\n",
        "    for ann in annotations:\n",
        "        if ann[\"id\"] != ann[\"obj_ann_id\"]:\n",
        "            ann_id_to_anns[ann[\"obj_ann_id\"]][1].append(ann)\n",
        "    return ann_id_to_anns\n",
        "\n",
        "# Extract maps from dataset (for filtering and display).\n",
        "cat_id_to_name = {d[\"id\"]: d[\"name\"] for d in dataset[\"categories\"]}\n",
        "attr_id_to_name = {d[\"id\"]: d[\"name\"] for d in dataset[\"attributes\"]}\n",
        "image_id_to_image_file_name = {d[\"id\"]: os.path.join(image_root_dir, d[\"file_name\"]) for d in dataset[\"images\"]}\n",
        "obj_ann_id_to_anns = get_obj_and_part_anns(dataset[\"annotations\"])\n",
        "im_id_to_anns = defaultdict(list)\n",
        "im_id_to_cats = defaultdict(set)\n",
        "for ann, part_anns in obj_ann_id_to_anns.values():\n",
        "    im_id_to_anns[ann[\"image_id\"]].append((ann, part_anns))\n",
        "    im_id_to_cats[ann[\"image_id\"]].add(ann[\"category_id\"])\n",
        "im_id_to_im_area = {d[\"id\"]: d[\"height\"] * d[\"width\"] for d in dataset[\"images\"]}\n",
        "im_id_to_mean_box_area = {}\n",
        "for im_id, anns in im_id_to_anns.items():\n",
        "    im_area = im_id_to_im_area[im_id]\n",
        "    box_areas = {ann[\"area\"] for ann, _ in anns}\n",
        "    im_id_to_mean_box_area[im_id] = sum(box_areas) / len(box_areas) / im_area"
      ],
      "metadata": {
        "id": "QIgM6x_sC6Ru"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "dummy_meta = MetadataCatalog.get(\"sem2\").set(\n",
        "    stuff_classes = ['' for _i in range(76)],\n",
        "    stuff_colors = [(0, 0, 255)] * 75 + [(255, 255, 255)]\n",
        ")\n",
        "\n",
        "def get_image_with_boxes(im_fn, anns, cat_id_to_name):\n",
        "    \"\"\"\n",
        "    Reads the image, overlays boxes, and returns a numpy array with an image in RGB format.\n",
        "    \"\"\"\n",
        "    # Load image.\n",
        "    im = np.asarray(Image.open(im_fn))\n",
        "\n",
        "    # Extract boxes (in XYXY format) and labels.\n",
        "    boxes = []\n",
        "    labels = []\n",
        "    for ann, _ in anns:\n",
        "        boxes.append(ann[\"bbox\"])\n",
        "        labels.append(cat_id_to_name[ann[\"category_id\"]].split(\"_(\")[0])\n",
        "    boxes = np.array(boxes)\n",
        "    boxes[:, 2:] += boxes[:, :2]\n",
        "\n",
        "    # Use LVIS color list (https://github.com/lvis-dataset/lvis-api/blob/master/lvis/colormap.py).\n",
        "    color_list = np.array([0.000, 0.447, 0.741, 0.850, 0.325, 0.098, 0.929, 0.694, 0.125, 0.494, 0.184, 0.556, 0.466, 0.674, 0.188, 0.301, 0.745, 0.933, 0.635, 0.078, 0.184, 0.300, 0.300, 0.300, 0.600, 0.600, 0.600, 1.000, 0.000, 0.000, 1.000, 0.500, 0.000, 0.749, 0.749, 0.000, 0.000, 1.000, 0.000, 0.000, 0.000, 1.000, 0.667, 0.000, 1.000, 0.333, 0.333, 0.000, 0.333, 0.667, 0.000, 0.333, 1.000, 0.000, 0.667, 0.333, 0.000, 0.667, 0.667, 0.000, 0.667, 1.000, 0.000, 1.000, 0.333, 0.000, 1.000, 0.667, 0.000, 1.000, 1.000, 0.000, 0.000, 0.333, 0.500, 0.000, 0.667, 0.500, 0.000, 1.000, 0.500, 0.333, 0.000, 0.500, 0.333, 0.333, 0.500, 0.333, 0.667, 0.500, 0.333, 1.000, 0.500, 0.667, 0.000, 0.500, 0.667, 0.333, 0.500, 0.667, 0.667, 0.500, 0.667, 1.000, 0.500, 1.000, 0.000, 0.500, 1.000, 0.333, 0.500, 1.000, 0.667, 0.500, 1.000, 1.000, 0.500, 0.000, 0.333, 1.000, 0.000, 0.667, 1.000, 0.000, 1.000, 1.000, 0.333, 0.000, 1.000, 0.333, 0.333, 1.000, 0.333, 0.667, 1.000, 0.333, 1.000, 1.000, 0.667, 0.000, 1.000, 0.667, 0.333, 1.000, 0.667, 0.667, 1.000, 0.667, 1.000, 1.000, 1.000, 0.000, 1.000, 1.000, 0.333, 1.000, 1.000, 0.667, 1.000, 0.167, 0.000, 0.000, 0.333, 0.000, 0.000, 0.500, 0.000, 0.000, 0.667, 0.000, 0.000, 0.833, 0.000, 0.000, 1.000, 0.000, 0.000, 0.000, 0.167, 0.000, 0.000, 0.333, 0.000, 0.000, 0.500, 0.000, 0.000, 0.667, 0.000, 0.000, 0.833, 0.000, 0.000, 1.000, 0.000, 0.000, 0.000, 0.167, 0.000, 0.000, 0.333, 0.000, 0.000, 0.500, 0.000, 0.000, 0.667, 0.000, 0.000, 0.833, 0.000, 0.000, 1.000, 0.000, 0.000, 0.000, 0.143, 0.143, 0.143, 0.286, 0.286, 0.286, 0.429, 0.429, 0.429, 0.571, 0.571, 0.571, 0.714, 0.714, 0.714, 0.857, 0.857, 0.857, 1.000, 1.000, 1.000])\n",
        "    color_list = color_list.astype(np.float32).reshape((-1, 3))\n",
        "    box_colors = [color_list[idx % len(color_list)] for idx in range(len(boxes))]\n",
        "\n",
        "    # Overlay boxes.\n",
        "    viz = Visualizer(im, dummy_meta)\n",
        "    im_w_boxes = viz.overlay_instances(\n",
        "        labels=labels,\n",
        "        boxes=boxes,\n",
        "        masks=None,\n",
        "        keypoints=None,\n",
        "        assigned_colors=box_colors,\n",
        "    ).get_image()\n",
        "\n",
        "    return im_w_boxes\n",
        "\n",
        "def get_image_with_masks(im_fn, anns, cat_id_to_name, mask_type=\"part\"):\n",
        "    \"\"\"\n",
        "    Reads the image, overlays masks, and returns a numpy array with an image in RGB format.\n",
        "    \"\"\"\n",
        "    # Load image.\n",
        "    im = np.asarray(Image.open(im_fn))\n",
        "\n",
        "    # Build overlay masks and labels.\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for ann, part_anns in anns:\n",
        "        if mask_type == \"part\":\n",
        "            for part_ann in part_anns:\n",
        "                if part_ann[\"segmentation\"] != []:\n",
        "                    masks.append(part_ann[\"segmentation\"])\n",
        "                    labels.append(cat_id_to_name[part_ann[\"category_id\"]].split(\":\")[-1])\n",
        "        else:\n",
        "            if ann[\"segmentation\"] != []:\n",
        "                masks.append(ann[\"segmentation\"])\n",
        "                labels.append(cat_id_to_name[ann[\"category_id\"]].split(\"_(\")[0])\n",
        "\n",
        "    # Use LVIS color list (https://github.com/lvis-dataset/lvis-api/blob/master/lvis/colormap.py).\n",
        "    color_list = np.array([0.000, 0.447, 0.741, 0.850, 0.325, 0.098, 0.929, 0.694, 0.125, 0.494, 0.184, 0.556, 0.466, 0.674, 0.188, 0.301, 0.745, 0.933, 0.635, 0.078, 0.184, 0.300, 0.300, 0.300, 0.600, 0.600, 0.600, 1.000, 0.000, 0.000, 1.000, 0.500, 0.000, 0.749, 0.749, 0.000, 0.000, 1.000, 0.000, 0.000, 0.000, 1.000, 0.667, 0.000, 1.000, 0.333, 0.333, 0.000, 0.333, 0.667, 0.000, 0.333, 1.000, 0.000, 0.667, 0.333, 0.000, 0.667, 0.667, 0.000, 0.667, 1.000, 0.000, 1.000, 0.333, 0.000, 1.000, 0.667, 0.000, 1.000, 1.000, 0.000, 0.000, 0.333, 0.500, 0.000, 0.667, 0.500, 0.000, 1.000, 0.500, 0.333, 0.000, 0.500, 0.333, 0.333, 0.500, 0.333, 0.667, 0.500, 0.333, 1.000, 0.500, 0.667, 0.000, 0.500, 0.667, 0.333, 0.500, 0.667, 0.667, 0.500, 0.667, 1.000, 0.500, 1.000, 0.000, 0.500, 1.000, 0.333, 0.500, 1.000, 0.667, 0.500, 1.000, 1.000, 0.500, 0.000, 0.333, 1.000, 0.000, 0.667, 1.000, 0.000, 1.000, 1.000, 0.333, 0.000, 1.000, 0.333, 0.333, 1.000, 0.333, 0.667, 1.000, 0.333, 1.000, 1.000, 0.667, 0.000, 1.000, 0.667, 0.333, 1.000, 0.667, 0.667, 1.000, 0.667, 1.000, 1.000, 1.000, 0.000, 1.000, 1.000, 0.333, 1.000, 1.000, 0.667, 1.000, 0.167, 0.000, 0.000, 0.333, 0.000, 0.000, 0.500, 0.000, 0.000, 0.667, 0.000, 0.000, 0.833, 0.000, 0.000, 1.000, 0.000, 0.000, 0.000, 0.167, 0.000, 0.000, 0.333, 0.000, 0.000, 0.500, 0.000, 0.000, 0.667, 0.000, 0.000, 0.833, 0.000, 0.000, 1.000, 0.000, 0.000, 0.000, 0.167, 0.000, 0.000, 0.333, 0.000, 0.000, 0.500, 0.000, 0.000, 0.667, 0.000, 0.000, 0.833, 0.000, 0.000, 1.000, 0.000, 0.000, 0.000, 0.143, 0.143, 0.143, 0.286, 0.286, 0.286, 0.429, 0.429, 0.429, 0.571, 0.571, 0.571, 0.714, 0.714, 0.714, 0.857, 0.857, 0.857, 1.000, 1.000, 1.000])\n",
        "    color_list = color_list.astype(np.float32).reshape((-1, 3))\n",
        "    mask_colors = [color_list[idx % len(color_list)] for idx in range(len(masks))]\n",
        "\n",
        "    # Overlay masks.\n",
        "    viz = Visualizer(im, dummy_meta)\n",
        "    im_w_masks = viz.overlay_instances(\n",
        "        labels=labels,\n",
        "        boxes=None,\n",
        "        masks=masks,\n",
        "        keypoints=None,\n",
        "        assigned_colors=mask_colors,\n",
        "    ).get_image()\n",
        "\n",
        "    return im_w_masks\n",
        "\n",
        "def get_text_markdown(anns, cat_id_to_name, attr_id_to_name, font_size=19):\n",
        "    \"\"\"\n",
        "    Prepares markdown for object and part attributes text display.\n",
        "    \"\"\"\n",
        "    table_cell_strings = []\n",
        "    for ann, part_anns in anns:\n",
        "        # Show attribute text only for annotated boxes.\n",
        "        if len(set(ann[\"attribute_ids\"] + sum([part_ann[\"attribute_ids\"] for part_ann in part_anns], start=[]))) == 0:\n",
        "            continue\n",
        "        obj_name = cat_id_to_name[ann[\"category_id\"]].split('_(')[0]\n",
        "        obj_attrs = [attr_id_to_name[attr_id] for attr_id in ann[\"attribute_ids\"]]\n",
        "        part_name_to_attrs = {}\n",
        "        for part_ann in part_anns:\n",
        "            part_name = cat_id_to_name[part_ann[\"category_id\"]].replace(\":\", \"-\")\n",
        "            part_name_to_attrs[part_name] = [attr_id_to_name[attr_id] for attr_id in part_ann[\"attribute_ids\"]]\n",
        "        format_string = [f\"<u>{obj_name}</u>: \" + \", \".join(obj_attrs)]\n",
        "        for part_name, part_attrs in sorted(part_name_to_attrs.items(), key=lambda x: x[0]):\n",
        "            if len(part_attrs) > 0:\n",
        "                format_string.append(f\"<u>{part_name}</u>: \" + \", \".join(part_attrs))\n",
        "        format_string = \"<br>\".join(format_string)\n",
        "        format_string = f'<td style=\"padding: 0 0; vertical-align: top\"><p style=\"border-width:1px; border-style:solid; border-color:black; padding: 3px; font-size: {font_size}px;\"><b>' + format_string + \" </b></p><td>\"\n",
        "        table_cell_strings.append(format_string)\n",
        "    return Markdown(\"\".join('<table><tr>' + \"\".join(table_cell_strings) + \"<tr><table>\"))"
      ],
      "metadata": {
        "id": "lSjTbRB-DCw7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vis_offset = 0                     # Offset into the list of images to display\n",
        "vis_num_im = 10                    # Number of images to display\n",
        "vis_im_ids = None                  # A user specified list of image IDs to display, set to None to disable\n",
        "vis_num_cats = {2, 3}              # Include only images that have the number of categories in this set, set to None to disable\n",
        "vis_num_boxes = set(range(10))     # Include only images that have the number of boxes in this set, set to None to disable\n",
        "vis_num_parts = set(range(6, 15))  # Include only images that have the number of parts in this set, set to None to disable\n",
        "vis_mask_type = \"part\"             # Mask type, one of \"part\" or \"obj\"\n",
        "\n",
        "if vis_im_ids:\n",
        "    im_ids = vis_im_ids\n",
        "else:\n",
        "    # Start with all images.\n",
        "    im_ids = im_id_to_anns.keys()\n",
        "    # Select images satisfying a limit on the number of categories.\n",
        "    if vis_num_cats is not None:\n",
        "        im_ids = [im_id for im_id in im_ids if len(im_id_to_cats[im_id]) in vis_num_cats]\n",
        "    # Further select a subset of images satisfying a limit on the number of boxes.\n",
        "    if vis_num_boxes is not None:\n",
        "        im_ids = [im_id for im_id in im_ids if len(im_id_to_anns[im_id]) in vis_num_boxes]\n",
        "    # Narrow down further by limiting the number of part annotations.\n",
        "    if vis_num_parts is not None:\n",
        "        im_ids = [im_id for im_id in im_ids if len(sum(list(zip(*im_id_to_anns[im_id]))[1], start=[])) in vis_num_parts]\n",
        "    # Sort by box area.\n",
        "    im_ids = set(im_ids)\n",
        "    im_ids = [im_id for im_id, mean_box_area in sorted(im_id_to_mean_box_area.items(), key=lambda x: x[1], reverse=True) if im_id in im_ids]\n",
        "print(\"Number of images to visualize:\", len(im_ids))\n",
        "\n",
        "for im_id in im_ids[vis_offset:vis_offset+vis_num_im]:\n",
        "    im_fn = image_id_to_image_file_name[im_id]\n",
        "    anns = im_id_to_anns[im_id]\n",
        "    im1 = get_image_with_boxes(im_fn, anns, cat_id_to_name)\n",
        "    im2 = get_image_with_masks(im_fn, anns, cat_id_to_name, vis_mask_type)\n",
        "    im = Image.fromarray(np.concatenate([im1, im2], axis=1))\n",
        "    print(\"Image ID:\", im_id)\n",
        "    display(im)\n",
        "    display(get_text_markdown(anns, cat_id_to_name, attr_id_to_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "343B4ElrDH5C",
        "outputId": "22d9dfc6-f8d0-43d0-b77c-a6ac354f7c48"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images to visualize: 1423\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'datasets/coco/val2017/000000293044.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-308703182fb2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mim_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_id_to_image_file_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_id_to_anns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_with_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_id_to_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_with_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_id_to_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_mask_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-15160f3db625>\u001b[0m in \u001b[0;36mget_image_with_boxes\u001b[0;34m(im_fn, anns, cat_id_to_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Load image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Extract boxes (in XYXY format) and labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/coco/val2017/000000293044.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir()\n",
        "%cd detectron2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lFjQJBXwS4b",
        "outputId": "465b9649-447c-49f6-c7d1-016c468ada24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/detectron2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fvcore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax1GrGWJwitq",
        "outputId": "2c162293-aba4-468d-d150-9f11b5b082c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.14.0)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=6242ac2e51178abaca18cc7c863fe57eb84a080a2508ffe1d953420b8527c95e\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=5c3ceb7d3c5392d75d15bdd387553927714623f348f0863dac954d62ce882747\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.1.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This file borrows code from https://github.com/facebookresearch/detectron2/blob/main/detectron2/data/datasets/lvis.py\n",
        "\n",
        "This file contains functions to parse LVIS-format annotations into dicts in the\n",
        "\"Detectron2 format\".\n",
        "\"\"\"\n",
        "import logging\n",
        "import os\n",
        "\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.utils.file_io import PathManager\n",
        "from fvcore.common.timer import Timer\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "hCsZwpv3v_H1",
        "outputId": "617d42e9-90a1-4683-f46e-13c1651af1bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'paco.data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-eaa76ec4b14a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfvcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpaco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_mapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mATTR_TYPE_BG_IDXS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m from .paco_categories import (\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'paco.data'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../paco"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ewEOOlwzOg",
        "outputId": "94715502-db37-4d11-8a25-78d3620615bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/paco\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd paco"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIMH9_HXxK9k",
        "outputId": "4f197ab5-f7bc-489b-9fb7-ce6a58faa263"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/paco/paco\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQXk_-O1xAQ1",
        "outputId": "d8a1f422-7487-414f-aea1-6d53730d44eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/paco\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "16wOt3O8yMWM",
        "outputId": "eb0b87e4-f571-4cdc-80b6-46525212f68f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "attempted relative import with no known parent package",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8fe3591b4675>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpaco\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from paco.data.dataset_mapper import ATTR_TYPE_BG_IDXS\n",
        "\n",
        "from .paco_categories import (\n",
        "    PACO_ATTRIBUTES,\n",
        "    PACO_CATEGORIES,\n",
        "    PACO_CATEGORIES_COUNT,\n",
        "    PACO_PART_CATEGORIES,\n",
        ")\n",
        "\n",
        "from .paco_lvis_category_image_count import PACO_LVIS_CATEGORY_IMAGE_COUNT\n",
        "from .paco_lvis_ego4d_category_image_count import PACO_LVIS_EGO4D_CATEGORY_IMAGE_COUNT\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "__all__ = [\"load_json\", \"register_instances\", \"get_instances_meta\"]\n",
        "\n",
        "\n",
        "def register_instances(name, metadata, json_file, image_root):\n",
        "    DatasetCatalog.register(name, lambda: load_json(json_file, image_root, name))\n",
        "    MetadataCatalog.get(name).set(\n",
        "        json_file=json_file, image_root=image_root, evaluator_type=\"lvis\", **metadata\n",
        "    )\n",
        "\n",
        "\n",
        "def load_json(json_file, image_root, dataset_name=None, extra_annotation_keys=None):\n",
        "    \"\"\"\n",
        "    Load a json file in LVIS's annotation format.\n",
        "\n",
        "    Args:\n",
        "        Same as D2 LVIS dataset\n",
        "    Returns:\n",
        "        list[dict]: a list of dicts in Detectron2 standard format. (See\n",
        "        `Using Custom Datasets </tutorials/datasets.html>`_ )\n",
        "\n",
        "    Notes:\n",
        "        1. This function does not read the image files.\n",
        "           The results do not have the \"image\" field.\n",
        "    \"\"\"\n",
        "    from lvis import LVIS\n",
        "\n",
        "    json_file = PathManager.get_local_path(json_file)\n",
        "\n",
        "    timer = Timer()\n",
        "    lvis_api = LVIS(json_file)\n",
        "    if timer.seconds() > 1:\n",
        "        logger.info(\n",
        "            \"Loading {} takes {:.2f} seconds.\".format(json_file, timer.seconds())\n",
        "        )\n",
        "\n",
        "    if dataset_name is not None:\n",
        "        meta = get_instances_meta(dataset_name)\n",
        "        MetadataCatalog.get(dataset_name).set(**meta)\n",
        "\n",
        "    # sort indices for reproducible results\n",
        "    img_ids = sorted(lvis_api.imgs.keys())\n",
        "    # imgs is a list of dicts, each looks something like:\n",
        "    # {'license': 4,\n",
        "    #  'url': 'http://farm6.staticflickr.com/5454/9413846304_881d5e5c3b_z.jpg',\n",
        "    #  'file_name': 'COCO_val2014_000000001268.jpg',\n",
        "    #  'height': 427,\n",
        "    #  'width': 640,\n",
        "    #  'date_captured': '2013-11-17 05:57:24',\n",
        "    #  'id': 1268}\n",
        "    imgs = lvis_api.load_imgs(img_ids)\n",
        "    # anns is a list[list[dict]], where each dict is an annotation\n",
        "    # record for an object. The inner list enumerates the objects in an image\n",
        "    # and the outer list enumerates over images. Example of anns[0]:\n",
        "    # [{'segmentation': [[192.81,\n",
        "    #     247.09,\n",
        "    #     ...\n",
        "    #     219.03,\n",
        "    #     249.06]],\n",
        "    #   'area': 1035.749,\n",
        "    #   'image_id': 1268,\n",
        "    #   'bbox': [192.81, 224.8, 74.73, 33.43],\n",
        "    #   'category_id': 16,\n",
        "    #   'id': 42986},\n",
        "    #  ...]\n",
        "    anns = [lvis_api.img_ann_map[img_id] for img_id in img_ids]\n",
        "\n",
        "    # Sanity check that each annotation has a unique id\n",
        "    ann_ids = [ann[\"id\"] for anns_per_image in anns for ann in anns_per_image]\n",
        "    assert len(set(ann_ids)) == len(\n",
        "        ann_ids\n",
        "    ), \"Annotation ids in '{}' are not unique\".format(json_file)\n",
        "\n",
        "    imgs_anns = list(zip(imgs, anns))\n",
        "\n",
        "    logger.info(\n",
        "        \"Loaded {} images in the LVIS format from {}\".format(len(imgs_anns), json_file)\n",
        "    )\n",
        "\n",
        "    if extra_annotation_keys:\n",
        "        logger.info(\n",
        "            \"The following extra annotation keys will be loaded: {} \".format(\n",
        "                extra_annotation_keys\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        extra_annotation_keys = []\n",
        "\n",
        "    def get_file_name(img_root, img_dict):\n",
        "        # Determine the path from the file_name field\n",
        "        file_name = img_dict[\"file_name\"]\n",
        "        return os.path.join(img_root, file_name)\n",
        "\n",
        "    dataset_dicts = []\n",
        "\n",
        "    for (img_dict, anno_dict_list) in imgs_anns:\n",
        "        record = {}\n",
        "\n",
        "        record[\"file_name\"] = get_file_name(image_root, img_dict)\n",
        "        record[\"height\"] = img_dict[\"height\"]\n",
        "        record[\"width\"] = img_dict[\"width\"]\n",
        "        record[\"not_exhaustive_category_ids\"] = img_dict.get(\n",
        "            \"not_exhaustive_category_ids\", []\n",
        "        )\n",
        "        record[\"neg_category_ids\"] = img_dict.get(\"neg_category_ids\", [])\n",
        "        image_id = record[\"image_id\"] = img_dict[\"id\"]\n",
        "\n",
        "        objs = []\n",
        "        for anno in anno_dict_list:\n",
        "            # Check that the image_id in this annotation is the same as\n",
        "            # the image_id we're looking at.\n",
        "            # This fails only when the data parsing logic or the annotation\n",
        "            # file is buggy.\n",
        "            assert anno[\"image_id\"] == image_id\n",
        "            obj = {\"bbox\": anno[\"bbox\"], \"bbox_mode\": BoxMode.XYWH_ABS}\n",
        "\n",
        "            if dataset_name is not None and \"thing_dataset_id_to_contiguous_id\" in meta:\n",
        "                obj[\"category_id\"] = meta[\"thing_dataset_id_to_contiguous_id\"][\n",
        "                    anno[\"category_id\"]\n",
        "                ]\n",
        "            else:\n",
        "                obj[\"category_id\"] = (\n",
        "                    anno[\"category_id\"] - 1\n",
        "                )  # Convert 1-indexed to 0-indexed\n",
        "            segm = anno[\"segmentation\"]  # list[list[float]]\n",
        "\n",
        "            if len(segm) == 0:\n",
        "                continue\n",
        "            assert len(segm) > 0, segm\n",
        "            obj[\"segmentation\"] = segm\n",
        "            for extra_ann_key in extra_annotation_keys:\n",
        "                obj[extra_ann_key] = anno[extra_ann_key]\n",
        "\n",
        "            if \"attribute_ids\" in anno:\n",
        "                obj[\"attr_labels\"] = anno[\"attribute_ids\"]\n",
        "                obj[\"attr_ignores\"] = [\n",
        "                    anno[\"unknown_color\"],\n",
        "                    anno[\"unknown_pattern_marking\"],\n",
        "                    anno[\"unknown_material\"],\n",
        "                    anno[\"unknown_transparency\"],\n",
        "                ]\n",
        "            else:\n",
        "                obj[\"attr_labels\"] = ATTR_TYPE_BG_IDXS\n",
        "                obj[\"attr_ignores\"] = [1, 1, 1, 1]\n",
        "            objs.append(obj)\n",
        "\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "\n",
        "    return dataset_dicts\n",
        "\n",
        "\n",
        "def get_instances_meta(dataset_name):\n",
        "    # we assume that ego4d is always trained in conjunction with lvis\n",
        "    if \"ego4d\" in dataset_name or \"joint\" in dataset_name:\n",
        "        return _get_lvis_ego4d_instances_meta()\n",
        "    else:\n",
        "        return _get_lvis_instances_meta()\n",
        "\n",
        "\n",
        "def _get_object_and_attribute_classes():\n",
        "    assert len(PACO_CATEGORIES) == PACO_CATEGORIES_COUNT\n",
        "\n",
        "    # Ensure that the category list is sorted by id\n",
        "    categories = sorted(PACO_CATEGORIES, key=lambda x: x[\"id\"])\n",
        "    attribute_categories = sorted(PACO_ATTRIBUTES, key=lambda x: x[\"id\"])\n",
        "    part_categories = sorted(PACO_PART_CATEGORIES, key=lambda x: x[\"id\"])\n",
        "\n",
        "    thing_dataset_id_to_contiguous_id = {k[\"id\"]: _i for _i, k in enumerate(categories)}\n",
        "    thing_classes = [k[\"name\"] for k in categories]\n",
        "    attribute_classes = [k[\"name\"] for k in attribute_categories]\n",
        "    part_classes = [k[\"name\"] for k in part_categories]\n",
        "\n",
        "    return {\n",
        "        \"thing_classes\": thing_classes,\n",
        "        \"part_classes\": part_classes,\n",
        "        \"attribute_classes\": attribute_classes,\n",
        "        \"thing_dataset_id_to_contiguous_id\": thing_dataset_id_to_contiguous_id,\n",
        "    }\n",
        "\n",
        "\n",
        "def _get_lvis_instances_meta():\n",
        "    # Use this when training on PACO-LVIS and PACO-EGO4D jointly\n",
        "    # we do not currently support training only with ego4d data\n",
        "    metadata = _get_object_and_attribute_classes()\n",
        "    metadata[\"class_image_count\"] = PACO_LVIS_CATEGORY_IMAGE_COUNT\n",
        "    return metadata\n",
        "\n",
        "\n",
        "def _get_lvis_ego4d_instances_meta():\n",
        "    metadata = _get_object_and_attribute_classes()\n",
        "    metadata[\"class_image_count\"] = PACO_LVIS_EGO4D_CATEGORY_IMAGE_COUNT\n",
        "    return metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Ev4NF-2KwZqy",
        "outputId": "fdc8f085-a117-48c0-8cb4-f9e8a408ce46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'paco.data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b693dd5f8cac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpaco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_mapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mATTR_TYPE_BG_IDXS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m from .paco_categories import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mPACO_ATTRIBUTES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mPACO_CATEGORIES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'paco.data'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LzFhkYa1w2dX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}